{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "failing-satellite",
   "metadata": {},
   "source": [
    "# Saliency Detection / Prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-desperate",
   "metadata": {},
   "source": [
    "## Tematem owej prezentacji jest image salience prediction / detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-trigger",
   "metadata": {},
   "source": [
    "## Jest to problem związany z określeniem istotnych fragmentów zdjęcia. Istotność jest tu jednak pojęciem rozmytym."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-yugoslavia",
   "metadata": {},
   "source": [
    "Gdy taksówkarz kieruje pojazdem, istotne będą dla niego znaki drogowe, inne samochody, sygnalizacja, czy ogólnie sytuacja na drodze, a mniej reklamy na mijanych ścianach domów. Dla jego pasażera sytuacja może być całkiem odwrotna. Zatem określenie istotności dla podmiotu poznającego jest związane z akcją, którą podmiot ten aktualnie wykonuje, jego stanami wewnętrznymi. Taki pogląd na istotność obiektów zostanie omówiony w pierwszej kolejności. Takie podejście do silency detection używa się w Intepretable Machine Learning, gdzie bada się czy przetrenowany model dokonuje predykcji na podstawie cech istotnych dla klasy decyzyjnej, czy też wzorca właściwego dostępnym danym (na zdjęciu Husky występuje jedynie w śnieżnym krajobrazie, więc model przykłada równie istotną wagę do śniegu co do cech charakterystycznych dla Husky'ego)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-tomato",
   "metadata": {},
   "source": [
    "Po co przydaje się saliency detection:\n",
    "   > Interpretable Machine Learning: Wewnętrza ocena predykcji modelu\n",
    "   > Object Detection/Segmentation: Wyodrębnienie ze zdjęcia istotnych obiektów\n",
    "   > Wczesne przetworzenie danych: Wyodrębnienie istotniejszych części obrazu, pod zadanie właściwe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-tribe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Skoro "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-injury",
   "metadata": {},
   "source": [
    "## Saliency Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-probe",
   "metadata": {},
   "source": [
    "Saliency Maps to technika wizualizacji pozwalająca uzyskać lepszy wgląd w proces decyzyjny sieci neuronowej. Pomagają również wiedzieć, na czym skupia się każda warstwa warstwy splotowej. Pomaga nam to nieco lepiej zrozumieć proces podejmowania decyzji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-diagram",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "#Using VGG-19 pretrained model for image classification\n",
    "\n",
    "model = torchvision.models.vgg19(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-multimedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url,fname):\n",
    "    response = requests.get(url)\n",
    "    with open(fname,\"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    \n",
    "# Downloading the image    \n",
    "download(\"https://specials-images.forbesimg.com/imageserve/5db4c7b464b49a0007e9dfac/960x0.jpg?fit=scale\",\"input.jpg\")\n",
    "\n",
    "# Opening the image\n",
    "img = Image.open('input.jpg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-packing",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-fountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the image\n",
    "def preprocess(image, size=224):\n",
    "    transform = T.Compose([\n",
    "        T.Resize((size,size)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        T.Lambda(lambda x: x[None]),\n",
    "    ])\n",
    "    return transform(image)\n",
    "\n",
    "'''\n",
    "    Y = (X - μ)/(σ) => Y ~ Distribution(0,1) if X ~ Distribution(μ,σ)\n",
    "    => Y/(1/σ) follows Distribution(0,σ)\n",
    "    => (Y/(1/σ) - (-μ))/1 is actually X and hence follows Distribution(μ,σ)\n",
    "'''\n",
    "def deprocess(image):\n",
    "    transform = T.Compose([\n",
    "        T.Lambda(lambda x: x[0]),\n",
    "        T.Normalize(mean=[0, 0, 0], std=[4.3668, 4.4643, 4.4444]),\n",
    "        T.Normalize(mean=[-0.485, -0.456, -0.406], std=[1, 1, 1]),\n",
    "        T.ToPILImage(),\n",
    "    ])\n",
    "    return transform(image)\n",
    "\n",
    "def show_img(PIL_IMG):\n",
    "    plt.imshow(np.asarray(PIL_IMG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-withdrawal",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-mineral",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocess(img)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "X.requires_grad_()\n",
    "\n",
    "scores = model(X)\n",
    "\n",
    "score_max_index = scores.argmax()\n",
    "score_max = scores[0,score_max_index]\n",
    "\n",
    "score_max.backward()\n",
    "\n",
    "saliency, _ = torch.max(X.grad.data.abs(),dim=1)\n",
    "\n",
    "plt.imshow(saliency[0], cmap=plt.cm.hot)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-filling",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-purpose",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.grad.data.abs().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-tobago",
   "metadata": {},
   "outputs": [],
   "source": [
    "saliency, _ = torch.max(X.grad.data.abs(),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-sleeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "saliency.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-omaha",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tldl",
   "language": "python",
   "name": "tldl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

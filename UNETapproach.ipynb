{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "satellite-cleveland",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from PIL import Image\n",
    "from torchbearer.cv_utils import DatasetValidationSplitter\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "from torch import nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-award",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "\n",
    "def padding(img, shape_r=480, shape_c=640, channels=3):\n",
    "    img_padded = np.zeros((shape_r, shape_c, channels), dtype=np.uint8)\n",
    "    if channels == 1:\n",
    "        img_padded = np.zeros((shape_r, shape_c), dtype=np.uint8)\n",
    "\n",
    "    original_shape = img.shape\n",
    "    rows_rate = original_shape[0]/shape_r\n",
    "    cols_rate = original_shape[1]/shape_c\n",
    "\n",
    "    if rows_rate > cols_rate:\n",
    "        new_cols = (original_shape[1] * shape_r) // original_shape[0]\n",
    "        img = cv2.resize(img, (new_cols, shape_r))\n",
    "        if new_cols > shape_c:\n",
    "            new_cols = shape_c\n",
    "        img_padded[:, ((img_padded.shape[1] - new_cols) // 2):((img_padded.shape[1] - new_cols) // 2 + new_cols)] = img\n",
    "    else:\n",
    "        new_rows = (original_shape[0] * shape_c) // original_shape[1]\n",
    "        img = cv2.resize(img, (shape_c, new_rows))\n",
    "        if new_rows > shape_r:\n",
    "            new_rows = shape_r\n",
    "        img_padded[((img_padded.shape[0] - new_rows) // 2):((img_padded.shape[0] - new_rows) // 2 + new_rows), :] = img\n",
    "\n",
    "    return img_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-native",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cat200Loader:\n",
    "    def __init__(self, root_path, batch_size=8, frac_train_to_be_val=0.2):\n",
    "        self.datasets = {}\n",
    "        self.loaders = {}\n",
    "        imgs_path = lambda x: f'{root_path}/{x}/Stimuli/'\n",
    "        maps_path = lambda x: f'{root_path}/{x}/FIXATIONMAPS/'\n",
    "        \n",
    "        self.datasets['test'] = CustomImageDataset(imgs_path('test'), transform=transform1)\n",
    "        dataset = CustomImageDataset(imgs_path('train'), maps_path('train'), transform=transform1, target_transform=transform2)\n",
    "        splitter = DatasetValidationSplitter(len(dataset), frac_train_to_be_val)\n",
    "        self.datasets['val'] = splitter.get_val_dataset(dataset)\n",
    "        self.datasets['train'] = splitter.get_train_dataset(dataset)\n",
    "        \n",
    "        self.loaders['train'] = DataLoader(self.datasets['train'], batch_size=batch_size, shuffle = True, pin_memory=True)\n",
    "        self.loaders['val'] = DataLoader(self.datasets['val'], batch_size=batch_size, shuffle = True, pin_memory=True)\n",
    "        self.loaders['test'] = DataLoader(self.datasets['test'], batch_size=batch_size, shuffle = False, pin_memory=True)\n",
    "        \n",
    "        \n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, imgs_path, fix_maps_path=None, transform=None, target_transform=None):\n",
    "        self.images = [os.path.join(imgs_path, category,img) for category in os.listdir(imgs_path)\n",
    "                                 for img in os.listdir(os.path.join(imgs_path, category)) if img.endswith('.jpg')]\n",
    "        self.maps = [os.path.join(fix_maps_path, category,img) for category in os.listdir(fix_maps_path)\n",
    "                                 for img in os.listdir(os.path.join(fix_maps_path, category)) if img.endswith('.jpg')] if fix_maps_path else None\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.norm = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(self.images[idx])\n",
    "        image = padding(image, image_size1, image_size2, 3).astype('float')\n",
    "        image = np.rollaxis(image, 2, 0)  \n",
    "        if self.maps:\n",
    "            fix_map = cv2.imread(self.maps[idx],0)\n",
    "            fix_map = padding(fix_map, shape_r_gt, shape_c_gt, 1).astype('float')\n",
    "        if self.transform:\n",
    "            image = torch.tensor(image,dtype=torch.float)\n",
    "            if image.shape[0] == 1:\n",
    "                image = image.expand(3,image_size1,image_size2)\n",
    "            image = self.norm(image)\n",
    "            if self.maps:\n",
    "                fix_map = torch.tensor(fix_map,dtype=torch.float)\n",
    "                fix_map = fix_map.repeat(1,8,8)\n",
    "        \n",
    "        catt = torch.cat([image, fix_map], 0)\n",
    "        return catt / 255.0, self.images[idx], self.maps[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "continent-saint",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, criterion, optimizer, loaders):\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = model.to(self.device)\n",
    "        self.criterion = criterion.to(self.device)\n",
    "        self.optimizer = optimizer\n",
    "        self.loaders = loaders\n",
    "        \n",
    "    def run_trainer(self, epochs):\n",
    "        liveloss = PlotLosses()\n",
    "        for epoch in range(epochs):\n",
    "            self.logs = {}\n",
    "            \n",
    "            self.model.train()\n",
    "            self.run_epoch('train', epoch)\n",
    "            \n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                self.run_epoch('val', epoch)\n",
    "                \n",
    "            liveloss.update(self.logs)\n",
    "            liveloss.send()\n",
    "                \n",
    "    def run_epoch(self, phase, epoch):\n",
    "        running_loss = 0.0\n",
    "        for x, img, fmap in tqdm(self.loaders.loaders[phase]):\n",
    "            x_true, y_true = x[:,:-1,:,:], x[:,1,:shape_r_gt,:shape_c_gt].unsqueeze(1)\n",
    "            x_true, y_true = x_true.to(self.device), y_true.to(self.device)\n",
    "            y_pred = self.model(x_true)\n",
    "            loss = self.criterion(y_pred, y_true, self.model.prior.clone())\n",
    "            if phase == 'train':\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "            running_loss += loss.detach() * x_true.size(0)\n",
    "            print(loss.detach())\n",
    "            if phase == 'val':\n",
    "                plt.imshow(x_true[0][0].data.cpu().numpy(),cmap='gray')\n",
    "                plt.show()\n",
    "                plt.imshow(y_pred[0][0].data.cpu().numpy(),cmap='gray')\n",
    "                plt.show()\n",
    "            \n",
    "        epoch_loss = running_loss / len(self.loaders.loaders[phase].dataset)\n",
    "        self.logs[f'{phase}_loss'] = epoch_loss.item()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-characteristic",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(3, 1)\n",
    "\n",
    "\n",
    "# freezing Layer\n",
    "# last_freeze_layer = 23\n",
    "# for i,param in enumerate(model.parameters()):\n",
    "#     if i < last_freeze_layer:\n",
    "#         param.requires_grad = False\n",
    "\n",
    "    \n",
    "criterion = ModMSELoss(shape_r_gt,shape_c_gt)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3,weight_decay=0.0005,momentum=0.9,nesterov=True)\n",
    "# optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "loaders = Cat200Loader('cat2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-luther",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, criterion, optimizer, loaders)\n",
    "\n",
    "trainer.run_trainer(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tldl",
   "language": "python",
   "name": "tldl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-delivery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "\n",
    "class Model():\n",
    "    def _init__(self):\n",
    "        self.pretrained_layer = torchvision.models.vgg19(pretrained=True)\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        pass\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-memorabilia",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-sentence",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-living",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = torchvision.models.resnet18(pretrained=True).eval()\n",
    "# hook the feature extractor\n",
    "# https://github.com/zhoubolei/CAM/blob/master/pytorch_CAM.py\n",
    "features_blobs = []\n",
    "def hook_feature(module, input, output):\n",
    "    features_blobs.append(output.data.cpu().numpy())\n",
    "model._modules.get('layer4').register_forward_hook(hook_feature)\n",
    "# get the softmax weight\n",
    "params = list(model.parameters())\n",
    "weight_softmax = np.squeeze(params[-2].data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-thursday",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-austin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-index",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose(\n",
    "    [transforms.Resize((224, 224)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-episode",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url,fname):\n",
    "    response = requests.get(url)\n",
    "    with open(fname,\"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    \n",
    "# Downloading the image    \n",
    "download(\"https://specials-images.forbesimg.com/imageserve/5db4c7b464b49a0007e9dfac/960x0.jpg?fit=scale\",\"input.jpg\")\n",
    "\n",
    "# Opening the image\n",
    "image = Image.open('input.jpg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-service",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-money",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-maldives",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('input.jpg')\n",
    "orig_image = image.copy()\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "height, width, _ = image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-copper",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "from torch import topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-commercial",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose(\n",
    "    [transforms.ToPILImage(),\n",
    "     transforms.Resize((224, 224)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-thirty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the image transforms\n",
    "image_tensor = transforms(image)\n",
    "# add batch dimension\n",
    "image_tensor = image_tensor.unsqueeze(0)\n",
    "# forward pass through model\n",
    "outputs = model(image_tensor)\n",
    "# get the softmax probabilities\n",
    "probs = F.softmax(outputs).data.squeeze()\n",
    "# get the class indices of top k probabilities\n",
    "class_idx = topk(probs, 1)[1].int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-jaguar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnCAM(feature_conv, weight_softmax, class_idx):\n",
    "    # generate the class activation maps upsample to 256x256\n",
    "    size_upsample = (256, 256)\n",
    "    bz, nc, h, w = feature_conv.shape\n",
    "    output_cam = []\n",
    "    for idx in class_idx:\n",
    "        cam = weight_softmax[idx].dot(feature_conv.reshape((nc, h*w)))\n",
    "        cam = cam.reshape(h, w)\n",
    "        cam = cam - np.min(cam)\n",
    "        cam_img = cam / np.max(cam)\n",
    "        cam_img = np.uint8(255 * cam_img)\n",
    "        output_cam.append(cv2.resize(cam_img, size_upsample))\n",
    "    return output_cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-guatemala",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_cam(CAMs, width, height, orig_image, class_idx, all_classes, save_name):\n",
    "    for i, cam in enumerate(CAMs):\n",
    "        heatmap = cv2.applyColorMap(cv2.resize(cam,(width, height)), cv2.COLORMAP_JET)\n",
    "        result = heatmap * 0.3 + orig_image * 0.5\n",
    "        # put class label text on the result\n",
    "        cv2.putText(result, all_classes[class_idx[i]], (20, 40), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 2)\n",
    "        cv2.imshow('CAM', result/255.)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.imwrite(f\"outputs/CAM_{save_name}.jpg\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-street",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAMs = returnCAM(features_blobs[0], weight_softmax, class_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-spectrum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_synset_classes(file_path):\n",
    "    # load the synset text file for labels\n",
    "    all_classes = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        all_lines = f.readlines()\n",
    "        labels = [line.split('\\n') for line in all_lines]\n",
    "        for label_list in labels:\n",
    "            current_class = [name.split(',') for name in label_list][0][0][10:]\n",
    "            all_classes.append(current_class)\n",
    "    return all_classes\n",
    "# get all the classes in a list\n",
    "all_classes = load_synset_classes('LOC_synset_mapping.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-lafayette",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = 'name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-livestock",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_cam(CAMs, width, height, orig_image, class_idx, all_classes, save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-artwork",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tldl",
   "language": "python",
   "name": "tldl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
